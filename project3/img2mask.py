# -*- coding: utf-8 -*-
"""img2mask_2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W0nmwq94-hazu_TnyYbMX5P67HPvNfVj

generator : U-net

discriminator : binary

no gp, no sn, no sa;

# INSTALL TENSORFLOW
"""

# Commented out IPython magic to ensure Python compatibility.
# Tensorboard
! pip install --upgrade tensorflow-gpu 
! pip uninstall tensorflow-tensorboard
! pip install tensorboard

# To generate GIFs
!pip install -q imageio

# Load the TensorBoard notebook extension
# %load_ext tensorboard

import tensorflow as tf
print(tf.__version__)
print(str(tf.test.is_gpu_available()))

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive/')
# %cd /content/drive/'My Drive'/GAN/cycleGAN/
!ls

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir ./logs

"""# IMPORT"""

import os
import PIL
import time
import glob
import cv2
import imageio
import datetime
import matplotlib.pyplot as plt
import tensorflow as tf
import numpy as np
from tensorflow import keras
from tensorflow.keras import metrics
from IPython import display

# For FID
from numpy import cov
from numpy import trace
from numpy import iscomplexobj
from numpy import asarray
from numpy.random import shuffle
from scipy.linalg import sqrtm
from skimage.transform import resize


inception3 = tf.keras.applications.InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))

print(tf.__version__)
print(str(tf.test.is_gpu_available()))
!ls

HEIGHT = 300
WIDTH = 300
IMG_HEIGHT = 256
IMG_WIDTH = 256
DATA = './data/'
glamda = 10
dlamda = 0
batch_size = 64
begin = 0
start = 0
epochs = 1500
train_size = 640
# test_size = 320
drop_rate = 0.3
version = 'img2mask_2'
JJ = 4

"""# DATA"""

def convert_to_save(img):
  save_img = img * 0.5 + 0.5
  save_img = 255 * save_img
  save_img = tf.cast(save_img, tf.uint8)
  return save_img
  
def load_img(img_path, mask_path):
    input_image = tf.image.decode_jpeg(tf.io.read_file(img_path))
    msk_image = tf.image.decode_jpeg(tf.io.read_file(mask_path))
    input_image = tf.cast(input_image, tf.float32)
    msk_image = tf.cast(msk_image/80, tf.int32)
    msk_image = tf.image.random_crop(msk_image, [500, 500, 1])
    input_image = (input_image / 127.5) - 1
    
    return input_image, msk_image

def random_crop(img, msk):
    img = tf.image.resize(img, [HEIGHT, WIDTH], 'nearest')
    msk = tf.image.resize(msk, [HEIGHT, WIDTH], 'nearest')
    
    msk = tf.cast(msk, tf.float32)
    combined = tf.concat([img, msk], axis=2)
    combined = tf.image.random_crop(combined, [IMG_HEIGHT, IMG_WIDTH, 4])
    img = combined[:, :, :3]
    msk = combined[:, :, -1]
    msk = tf.expand_dims(msk, axis = 2) 
    
#     img = tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH], 'nearest')
#     msk = tf.image.resize(msk, [IMG_HEIGHT, IMG_WIDTH], 'nearest')
    
    msk = tf.cast(msk, tf.int32)
    
    return img, msk

def random_flip_horz_vert(img, msk):
    if tf.random.uniform(()) > 0.5:
        img = tf.image.flip_left_right(img)
        msk = tf.image.flip_left_right(msk)
    if tf.random.uniform(()) > 0.5:
        img = tf.image.flip_up_down(img)
        msk = tf.image.flip_up_down(msk)
    
    return img, msk
  

def random_rot(img, msk):
    k = tf.random.uniform([], minval = 0, maxval = 4, dtype = tf.int32)
    img = tf.image.rot90(img,  k)
    msk = tf.image.rot90(msk, k)
    return img, msk
  
def preprocess(img_path, mask_path):
    img, msk = load_img(img_path, mask_path)
    img, msk = random_crop(img, msk)
    img, msk = random_flip_horz_vert(img, msk)
    img, msk = random_rot(img, msk)
    return img, msk

def preprocess2(img_path, mask_path):
    img, msk = load_img(img_path, mask_path)
    img = tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH], 'nearest')
    msk = tf.image.resize(msk, [IMG_HEIGHT, IMG_WIDTH], 'nearest')

    return img, msk

listA = tf.data.Dataset.list_files(DATA + 'rename_img' +'/*.jpg', shuffle=False)
listB = tf.data.Dataset.list_files(DATA + 'rename_mask' + '/*.png', shuffle=False)

listA = [path for path in iter(listA)]
listB = [path for path in iter(listB)]

train_listA = listA[:train_size]
train_listB = listB[:train_size]
test_listA = listA[train_size:]
test_listB = listB[train_size:]

# train data
train_data = tf.data.Dataset.from_tensor_slices((train_listA, train_listB))
train_temp = train_data.map(preprocess2).batch(batch_size)
train_data = train_data.map(preprocess).shuffle(train_size).batch(batch_size)

# test data
test_data = tf.data.Dataset.from_tensor_slices((test_listA, test_listB))
test_temp = test_data.map(preprocess2).batch(batch_size)
test_data = test_data.map(preprocess2).batch(batch_size)


# print(train_data)
# print(next(iter(train_data))[0].shape)
# print(next(iter(train_data))[1].shape)

train_sample_img, train_sample_mask = next(iter(train_temp))
print('train_sample_img:', train_sample_img.shape, train_sample_img.dtype, train_sample_img.numpy().min(), train_sample_img.numpy().max())
print('train_sample_mask:', train_sample_mask.shape, train_sample_mask.dtype, train_sample_mask.numpy().min(), train_sample_mask.numpy().max())


test_sample_img, test_sample_mask = next(iter(test_temp))
print('test_sample_img:', test_sample_img.shape, test_sample_img.dtype, test_sample_img.numpy().min(), test_sample_img.numpy().max())
print('test_sample_mask:', test_sample_mask.shape, test_sample_mask.dtype, test_sample_mask.numpy().min(), test_sample_mask.numpy().max())

i = 0
plt.figure(figsize=(20, 20))

plt.subplot(221)
plt.title('image')
plt.imshow(train_sample_img[i] * 0.5 + 0.5)

train_sample_mask = tf.cast(train_sample_mask, tf.float32)
test_sample_mask = tf.cast(test_sample_mask, tf.float32)

plt.subplot(222)
plt.title('mask')
plt.imshow(tf.squeeze(train_sample_mask[i])/3.0, 'gray')

plt.subplot(223)
plt.title('image')
plt.imshow(test_sample_img[i] * 0.5 + 0.5)

plt.subplot(224)
plt.title('mask')
plt.imshow(tf.squeeze(test_sample_mask[i])/3.0, 'gray')

print('img: ')
print(tf.reduce_min(train_sample_img))
print(tf.reduce_max(train_sample_img))

print('msk:')
print(tf.reduce_min(train_sample_mask))
print(tf.reduce_max(train_sample_mask))

print('img: ')
print(tf.reduce_min(test_sample_img))
print(tf.reduce_max(test_sample_img))

print('msk:')
print(tf.reduce_min(test_sample_mask))
print(tf.reduce_max(test_sample_mask))

# def convert_to_save(img):
#   img = img * 0.5 + 0.5
#   img = 255 * img
#   img = tf.cast(img, tf.uint8)
#   return img

# # origin = train_sample_img.numpy()
# rescale = convert_to_save(train_sample_img).numpy()
# for i in range(10):
#     # imageio.imwrite(DATA + 'fake/%d_origin.jpg'%i, origin[i])
#     imageio.imwrite(DATA + 'fake/%d_rescale.jpg'%i, rescale[i])

"""# Generator"""

class Downsample(keras.Model):

    def __init__(self, filters, size, apply_batchnorm=True):
        super(Downsample, self).__init__()
        
        self.apply_batchnorm = apply_batchnorm
        initializer = tf.random_normal_initializer(0., 0.02)

        self.conv1 = keras.layers.Conv2D(filters,
                                            (size, size),
                                            strides=2,
                                            padding='same',
                                            kernel_initializer=initializer,
                                            use_bias=False)
        if self.apply_batchnorm:
            self.batchnorm = keras.layers.BatchNormalization()

    def call(self, x, training):
        x = self.conv1(x)
        if self.apply_batchnorm:
            x = self.batchnorm(x, training=training)
        x = tf.nn.leaky_relu(x)
        return x


class Upsample(keras.Model):

    def __init__(self, filters, size, apply_dropout=False):
        super(Upsample, self).__init__()
        
        self.apply_dropout = apply_dropout
        initializer = tf.random_normal_initializer(0., 0.02)

        self.up_conv = keras.layers.Conv2DTranspose(filters,
                                                       (size, size),
                                                       strides=2,
                                                       padding='same',
                                                       kernel_initializer=initializer,
                                                       use_bias=False)
        self.batchnorm = keras.layers.BatchNormalization()
        if self.apply_dropout:
            self.dropout = keras.layers.Dropout(drop_rate)

    def call(self, x1, x2, training=None):

        x = self.up_conv(x1)
        x = self.batchnorm(x, training=training)
        if self.apply_dropout:
            x = self.dropout(x, training=training)
        x = tf.nn.relu(x)
        x = tf.concat([x, x2], axis=-1)
        return x
      
class GeneratorA2B(keras.Model):

    def __init__(self):
        super(GeneratorA2B, self).__init__()

        initializer = tf.random_normal_initializer(0., 0.02)

        self.down1 = Downsample(64, 4, apply_batchnorm=False)
        self.down2 = Downsample(128, 4)
        self.down3 = Downsample(256, 4)
        self.down4 = Downsample(512, 4)
        self.down5 = Downsample(512, 4)
        self.down6 = Downsample(512, 4)
        self.down7 = Downsample(512, 4)
        self.down8 = Downsample(512, 4)
        self.up1 = Upsample(512, 4, apply_dropout=True)
        self.up2 = Upsample(512, 4, apply_dropout=True)
        self.up3 = Upsample(512, 4, apply_dropout=True)
        self.up4 = Upsample(512, 4)
        self.up5 = Upsample(256, 4)
        self.up6 = Upsample(128, 4)
        self.up7 = Upsample(64, 4)

        self.last = keras.layers.Conv2DTranspose(4, (4, 4),
                                                    strides=2,
                                                    padding='same',
                                                    kernel_initializer=initializer)


    def call(self, inputs, training=None):
        # x shape == (bs, 256, 256, 4) 
        x = inputs   
        # x = tf.concat([x, noise], axis=-1)
        x1 = self.down1(x, training=training)  # (bs, 128, 128, 64)
        x2 = self.down2(x1, training=training)  # (bs, 64, 64, 128)
        x3 = self.down3(x2, training=training)  # (bs, 32, 32, 256)
        x4 = self.down4(x3, training=training)  # (bs, 16, 16, 512)
        x5 = self.down5(x4, training=training)  # (bs, 8, 8, 512)
        x6 = self.down6(x5, training=training)  # (bs, 4, 4, 512)
        x7 = self.down7(x6, training=training)  # (bs, 2, 2, 512)
        x8 = self.down8(x7, training=training)  # (bs, 1, 1, 512)

        x9 = self.up1(x8, x7, training=training)  # (bs, 2, 2, 1024)
        x10 = self.up2(x9, x6, training=training)  # (bs, 4, 4, 1024)
        x11 = self.up3(x10, x5, training=training)  # (bs, 8, 8, 1024)
        x12 = self.up4(x11, x4, training=training)  # (bs, 16, 16, 1024)
        x13 = self.up5(x12, x3, training=training)  # (bs, 32, 32, 512)
        x14 = self.up6(x13, x2, training=training)  # (bs, 64, 64, 256)
        x15 = self.up7(x14, x1, training=training)  # (bs, 128, 128, 128)

        x16 = self.last(x15)  # (bs, 256, 256, 3)
        x16 = tf.nn.tanh(x16)

        return x16

    def model(self):
        x = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_HEIGHT, 3], name='input_image')
        # seed = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_HEIGHT, 1], name='seed')
        return keras.Model(inputs=x, outputs=self.call(x))

"""# Discriminator"""

class DiscDownsample(keras.Model):

    def __init__(self, filters, size, apply_batchnorm=True):
        super(DiscDownsample, self).__init__()

        self.apply_batchnorm = apply_batchnorm
        initializer = tf.random_normal_initializer(0., 0.02)

        self.conv1 = keras.layers.Conv2D(filters, (size, size),
                                            strides=2,
                                            padding='same',
                                            kernel_initializer=initializer,
                                            use_bias=False)
        if self.apply_batchnorm:
            self.batchnorm = keras.layers.BatchNormalization()

    def call(self, x, training=None):

        x = self.conv1(x)
        if self.apply_batchnorm:
            x = self.batchnorm(x, training=training)
        x = tf.nn.leaky_relu(x)
        return x
      
class DiscriminatorB(keras.Model):

    def __init__(self):
        super(DiscriminatorB, self).__init__()

        initializer = tf.random_normal_initializer(0., 0.02)

        self.down1 = DiscDownsample(64, 4, False)
        self.down2 = DiscDownsample(128, 4)
        self.down3 = DiscDownsample(256, 4)
        self.down4 = DiscDownsample(256, 4)
        self.down5 = DiscDownsample(256, 4)
        self.down6 = DiscDownsample(256, 4)
        self.flatten = keras.layers.Flatten()
        self.dense = keras.layers.Dense(1)

        

    def call(self, inputs, training=None):
        inp, target = inputs

        # concatenating the input and the target
        x = tf.concat([inp, target], axis=-1)  # (bs, 256, 256, 7)
        x = self.down1(x, training=training)  # (bs, 128, 128, 64)
        x = self.down2(x, training=training)  # (bs, 64, 64, 128)
        x = self.down3(x, training=training)  # (bs, 32, 32, 256)
        x = self.down4(x, training=training)  # (bs, 16, 16, 256)
        x = self.down5(x, training=training)  # (bs, 8, 8, 256)
        x = self.down6(x, training=training)  # (bs, 4, 4, 256)
        x = self.flatten(x)                   # (bs, 4 * 4 * 256)
        x = self.dense(x)  # (bs, 1)
  
        return x
    
    def model(self):
        inp = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image')
        tar = tf.keras.layers.Input(shape=[256, 256, 4], name='target_image')
        return keras.Model(inputs=[inp,  tar], outputs=self.call([inp,  tar]))

# class DiscriminatorB(keras.Model):

#     def __init__(self):
#         super(DiscriminatorB, self).__init__()

#         initializer = tf.random_normal_initializer(0., 0.02)
#         self.down1 = DiscDownsample(64, 4, False)
#         self.down2 = DiscDownsample(128, 4)
#         self.down3 = DiscDownsample(256, 4)

#         self.zero_pad1 = keras.layers.ZeroPadding2D()
#         self.conv = keras.layers.Conv2D(512, (4, 4),
#                                            strides=1,
#                                            kernel_initializer=initializer,
#                                            use_bias=False)
#         self.batchnorm1 = keras.layers.BatchNormalization()

#         # shape change from (batch_size, 31, 31, 256) to (batch_size, 30, 30, 1)
#         self.zero_pad2 = keras.layers.ZeroPadding2D()
#         self.last = keras.layers.Conv2D(1, (4, 4),
#                                            strides=1,
#                                            kernel_initializer=initializer)


#     def call(self, inputs, training=None):
#         inp, target = inputs
#         x = tf.concat([inp, target], axis=-1) # (bs, 256, 256, 3 + 4)
#         x = self.down1(x, training=training)  # (bs, 128, 128, 64)
#         x = self.down2(x, training=training)  # (bs, 64, 64, 128)
#         x = self.down3(x, training=training)  # (bs, 32, 32, 256)

#         x = self.zero_pad1(x)  # (bs, 34, 34, 256)
#         x = self.conv(x)  # (bs, 34, 34, 512)
#         x = self.batchnorm1(x, training=training)
#         x = tf.nn.leaky_relu(x)

#         x = self.zero_pad2(x)  # (bs, 36, 36, 512)
#         # don't add a sigmoid activation here since
#         # the loss function expects raw logits.
#         x = self.last(x)  # (bs, 30, 30, 1)

#         return x
    
#     def model(self):
#         inp = tf.keras.layers.Input(shape=[128, 128, 3], name='input_image')
#         tar = tf.keras.layers.Input(shape=[128, 128, 4], name='target_image')
#         return keras.Model(inputs=[inp,  tar], outputs=self.call([inp,  tar]))

"""# test"""

generator1 = GeneratorA2B()
generator1.build(input_shape=(batch_size, 256, 256, 3))
generator1.model().summary()


discriminator = DiscriminatorB()
discriminator.build(input_shape=[(batch_size, 256, 256, 3), (batch_size, 256, 256, 4)])
discriminator.model().summary()

"""# Loss"""

binary_loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def generator_loss(disc_generated_output, gen_output, target, glamda=10):
    
    gan_loss = binary_loss_obj(tf.ones_like(disc_generated_output), disc_generated_output)
    
    l1_loss = tf.losses.categorical_crossentropy(target, gen_output, from_logits=True)
    l1_loss = tf.reduce_mean(l1_loss)
    
    gan_loss = tf.reduce_mean(gan_loss)

    total_gen_loss = gan_loss + glamda * l1_loss

    return total_gen_loss
   
def discriminator_loss(real_output, gen_output, dlamda=10):
  
    # real_output = discriminator([img, label], training=training)
    # gen_output = discriminator([gen_img, label], training=training)
    loss1 = binary_loss_obj(tf.ones_like(real_output), real_output)
    loss2 = binary_loss_obj(tf.zeros_like(gen_output), gen_output)
    # penalty = tf.reduce_mean(gradient_penalty(discriminator, img, gen_img, label))
    total = tf.reduce_mean(loss1) + tf.reduce_mean(loss2)
    # loss = total + dlamda * penalty
    
    return total
    # , penalty

"""# load model"""

discB = DiscriminatorB()
genA2B = GeneratorA2B()

genA2B_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
discB_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)

"""# Checkpoint"""

!rm -rf ./ckpt/$version

!mkdir ./ckpt/$version

checkpoint_dir = './ckpt/' + version + '/'
ckpt = tf.train.Checkpoint( genA2B=genA2B,
                            discB=discB,
                            genA2B_optimizer=genA2B_optimizer,
                            discB_optimizer=discB_optimizer)

ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_dir, max_to_keep=1)
# if a checkpoint exists, restore the latest checkpoint.
if ckpt_manager.latest_checkpoint:
    ckpt.restore(ckpt_manager.latest_checkpoint)
    print('Latest checkpoint restored!!', ckpt_manager.latest_checkpoint)
else:
    print("new training!")

"""# TOOL

## generate image
"""

def convert_mask(mask):
  mask = tf.math.softmax(mask, axis = 3)
  mask = tf.argmax(mask, axis = 3)    
  mask = tf.cast(mask, tf.float32)
  
  return mask

def generate_images(genA2B, img, mask, path, epoch):
  fake_mask = genA2B(img, training=True)
  mask = convert_mask(mask)
  fake_mask = convert_mask(fake_mask)
  
  for j in range(JJ):
    plt.figure(figsize=(15, 5))
    display_list = [img[j], mask[j], fake_mask[j]]
    title = ['img', 'mask', 'fake_mask']
    for i in range(3):
      plt.subplot(1, 3, i+1)
      plt.title(title[i])
      if i == 0:
        plt.imshow(display_list[i] * 0.5 + 0.5)
      else:
        plt.imshow(display_list[i]/3.0, 'gray')
      plt.axis('off')
    plt.savefig(path + '/{}_{:04d}.png'.format(j, epoch))
    plt.close()

  
def generate_all_images(genB2A, img, mask, path, begin):
  fake_mask = genA2B(img, training=True)
  mask = convert_mask(mask)
  fake_mask = convert_mask(fake_mask)
  
  for j in range(img.shape[0]):
    plt.figure(figsize=(15, 5))
    display_list = [img[j], mask[j], fake_img[j]]
    title = ['img', 'mask', 'fake_mask']
    for i in range(3):
      plt.subplot(1, 3, i+1)
      plt.title(title[i])
      if i == 0:
        plt.imshow(display_list[i] * 0.5 + 0.5)
      else:
        plt.imshow(display_list[i]/3.0, 'gray')
      plt.axis('off')
    plt.savefig(path + '/' + version +'_all_{:04d}.png'.format(begin + j))
    plt.close()

"""## FID"""

# def calculate_fid(model, images1, images2):
# 	# calculate activations
# 	act1 = model.predict(images1, steps=1)
# 	act2 = model.predict(images2, steps=1)
# 	# calculate mean and covariance statistics
# 	mu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)
# 	mu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)
# 	# calculate sum squared difference between means
# 	ssdiff = np.sum((mu1 - mu2)**2.0)
# 	# calculate sqrt of product between cov
# 	covmean = sqrtm(sigma1.dot(sigma2))
# 	# check and correct imaginary numbers from sqrt
# 	if iscomplexobj(covmean):
# 		covmean = covmean.real
# 	fid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)
# 	return fid
	
# def calculate_fid_with_img(img1, img2):
#  img1 = tf.image.resize(img1, [299, 299], 'nearest')
#  img2 = tf.image.resize(img2, [299, 299], 'nearest')
#  fid = calculate_fid(inception3, img1, img2)
#  return fid

# fid_score = calculate_fid_with_img(train_sample_img, test_sample_img)
# print(fid_score)

"""# LOGS"""

!rm -rf ./logs/$version

current_time = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
log_dir = './logs/' + version
train_summary_writer = tf.summary.create_file_writer(log_dir)

"""# Train step"""

train_metric = tf.keras.metrics.CategoricalAccuracy()

@tf.function
def train_step(trainA, trainB, metric, glamda, dlamda):
  with tf.GradientTape() as genA2B_tape, tf.GradientTape() as discB_tape:
      genA2B_output = genA2B(trainA, training=True)
      discB_real_output = discB([trainA, trainB], training=True)
      discB_fake_output = discB([trainA, genA2B_output], training=True)

      discB_loss = discriminator_loss(discB_real_output, discB_fake_output, dlamda)
      genA2B_loss= generator_loss(discB_fake_output, genA2B_output, trainB, glamda)

      # metrics.update_state(trainB, genA2B_output)
      train_metric.update_state(trainB, genA2B_output)

  genA2B_gradients = genA2B_tape.gradient(genA2B_loss, genA2B.trainable_variables)
  discB_gradients = discB_tape.gradient(discB_loss, discB.trainable_variables)

  genA2B_optimizer.apply_gradients(zip(genA2B_gradients, genA2B.trainable_variables))
  discB_optimizer.apply_gradients(zip(discB_gradients, discB.trainable_variables))

  return genA2B_loss, discB_loss

"""# Train"""

!rm -rf ./train/$version
!rm -rf ./test/$version

!mkdir ./train/$version
!mkdir ./test/$version

def train():
  train_temp_ = iter(train_temp)
  test_temp_  = iter(test_temp)
  train_sample_img, train_sample_mask = next(train_temp_)
  test_sample_img, test_sample_mask = next(test_temp_)
  train_sample_mask = tf.one_hot(tf.squeeze(train_sample_mask, axis=-1), 4, on_value=1.0, off_value=0.0, axis=3)
  test_sample_mask = tf.one_hot(tf.squeeze(test_sample_mask, axis=-1), 4, on_value=1.0, off_value=0.0, axis=3)
  
  print('batch_size:', batch_size, ', epochs:', epochs, ', glamda:', glamda, ', dlamda:', dlamda, ', drop_rate:', drop_rate)

  print('Begin time:{}.'.format( time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())))
  start_time = time.time()
  input_image = 0
  # train_metric = tf.keras.metrics.CategoricalAccuracy()
  test_metric = tf.keras.metrics.CategoricalAccuracy() 
  gloss_metric = tf.keras.metrics.Mean()
  dloss_metric = tf.keras.metrics.Mean()
  for epoch in range(start + 1, epochs + 1):

    train_metric.reset_states()
    test_metric.reset_states()
    gloss_metric.reset_states()
    dloss_metric.reset_states()

    for inputs in tf.data.Dataset.zip(train_data):
      input_image, target = inputs
      target = tf.one_hot(tf.squeeze(target, axis=-1), 4, on_value=1.0, off_value=0.0, axis=3)
      gloss, dloss = train_step(input_image, target, train_metric, dlamda=dlamda, glamda=glamda)
      gloss_metric.update_state(gloss)
      dloss_metric.update_state(dloss)
 
    if epoch % 50 == 0:
        ckpt_path = ckpt_manager.save()
        generate_images(genA2B, train_sample_img, train_sample_mask, './train/' + version, epoch)
        generate_images(genA2B, test_sample_img, test_sample_mask, './test/' + version, epoch)
  
    for inputs in tf.data.Dataset.zip(test_data):
        input_image, target = inputs
        target = tf.one_hot(tf.squeeze(target, axis=-1), 4, on_value=1.0, off_value=0.0, axis=3)
        genA2B_output = genA2B(input_image, training=True)
        test_metric.update_state(target, genA2B_output)
        
    with train_summary_writer.as_default():
      tf.summary.scalar('gloss',  gloss_metric.result().numpy(), step=epoch)
      tf.summary.scalar('dloss', dloss_metric.result().numpy(), step=epoch)
      tf.summary.scalar('train_acc', train_metric.result().numpy(), step=epoch)
      tf.summary.scalar('test_acc', test_metric.result().numpy(), step=epoch)
    if epoch % 10 == 0:
      print('Epoch: {}, Current time:{}, gloss:{:.2f},dloss:{:.2f},train_acc:{:.2f},test_acc:{:.2f}'.format(epoch, 
                                                                                                            time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()), 
                                                                                                            gloss_metric.result().numpy(),
                                                                                                            dloss_metric.result().numpy(),
                                                                                                            train_metric.result().numpy(), 
                                                                                                            test_metric.result().numpy()))
  
  ckpt_path = ckpt_manager.save()
  end_time = time.time()
  total_sec = end_time - start_time
  hours = int((total_sec)/(60*60))
  minitues = int((total_sec/60 - hours*60))
  seconds = int(total_sec - hours*3600 - minitues*60)
  print('End time:{}, total use time:{}hours, {}minitues, {}seconds.'.format(time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()), hours, minitues, seconds))

"""# Test"""

def test():
  begin = 0
  for inputs in tf.data.Dataset.zip(test_data_temp):
    input_image, target = inputs
    target = tf.one_hot(tf.squeeze(target, axis=-1), 4, on_value=1.0, off_value=0.0, axis=3)
    generate_all_images(genB2A, input_image, target, './test/' + version, begin)
    begin += batch_size
    print(begin)

"""# MAIN"""

# Commented out IPython magic to ensure Python compatibility.
# !kill 756
# %tensorboard --logdir ./logs

if __name__ == '__main__':
  if ckpt_manager.latest_checkpoint:
    ckpt.restore(ckpt_manager.latest_checkpoint)
    print('Latest checkpoint restored!!')
  else:
    print("new training!")
  print('\n-------------------------------------------TRAIN-------------------------------------------\n')
  train()

# start = 1500
# epochs = 3000

# if __name__ == '__main__':
#   if ckpt_manager.latest_checkpoint:
#     ckpt.restore(ckpt_manager.latest_checkpoint)
#     print('Latest checkpoint restored!!')
#   else:
#     print("new training!")
#   print('\n-------------------------------------------TRAIN-------------------------------------------\n')
#   train()

# listA = tf.data.Dataset.list_files(DATA + 'img' +'/*.jpg', shuffle=False)
# listB = tf.data.Dataset.list_files(DATA + 'mask' + '/*.png', shuffle=False)

# listA = [path for path in iter(listA)]
# listB = [path for path in iter(listB)]

# # train data
# for_augmentation = tf.data.Dataset.from_tensor_slices((listA, listB))
# for_augmentation = for_augmentation.map(preprocess2).batch(batch_size)

# j = 0
# title = ['img', 'mask', 'fake_img']
# for inputs in tf.data.Dataset.zip(for_augmentation):
#   input_image, target = inputs
#   target = tf.one_hot(tf.squeeze(target, axis=-1), 4, on_value=1.0, off_value=0.0, axis=3)
#   z = tf.random.normal([target.shape[0], IMG_HEIGHT, IMG_WIDTH, 1])
#   genB2A_output = genB2A([target, z], training=False)

#   genB2A_output = genB2A_output.numpy()
#   target = convert_mask(target)

#   for i in range(input_image.shape[0]):
#     plt.figure(figsize=(15, 5))
#     for k in range(3):
#       plt.subplot(1, 3, k+1)
#       plt.title(title[k])
#       if k == 0:
#         plt.imshow(input_image[i] * 0.5 + 0.5)
#       if k == 1:
#         plt.imshow(target[i]/3.0, 'gray')
#       if k == 2:
#         plt.imshow(genB2A_output[i] * 0.5 + 0.5)
#       plt.axis('off')
#     plt.savefig('./data/compare/comp_{:04d}.png'.format(i+j*batch_size))
#     plt.close()
   
#   j += 1
#   print('finish {:d} images!'.format(j * batch_size))